{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X1         X2 target\n",
      "0   16.263398  13.299206      r\n",
      "1    0.775408  23.986692      r\n",
      "2   29.170503  -3.287474      r\n",
      "3    6.739044 -28.033329      r\n",
      "4    3.216100  22.013695      r\n",
      "5   47.374906   7.925541      g\n",
      "6   24.064604  14.726109      r\n",
      "7   12.667897 -16.456068      r\n",
      "8    4.194880  20.421886      r\n",
      "9   48.451924   5.783617      g\n",
      "10  20.390478  -0.429726      r\n",
      "11  -9.861540  23.623534      r\n",
      "12   0.467438  24.894588      r\n",
      "13  -7.275756 -56.286623      g\n",
      "Index(['X1', 'X2', 'target'], dtype='object')\n",
      "(685, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://abtinshahidi.github.io/files/train_set.txt'\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=[\"X1\",\"X2\", \"target\"])  \n",
    "\n",
    "print(data.head(14))\n",
    "\n",
    "\n",
    "print(data.columns) \n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the target column\n",
    "one_hot_encoded_target = pd.get_dummies(data['target'], prefix='target')\n",
    "data = pd.concat([data, one_hot_encoded_target], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new features for project requirements\n",
    "data['X3'] = data['X1'] ** 2\n",
    "data['X4'] = data['X2'] ** 2\n",
    "data['X5'] = data['X1'] * data['X2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature column sets for each neural network model\n",
    "feature_sets = {\n",
    "    'X3_X4': ['X3', 'X4'],\n",
    "    'X3_X5': ['X3', 'X5'],\n",
    "    'X3_X4_X5': ['X3', 'X4', 'X5'],\n",
    "    'All': ['X1', 'X2', 'X3', 'X4', 'X5']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Neural Network Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = {\n",
    "    'hidden_layer_sizes': [(8,4),(16,8),(32,16),(64,32)],\n",
    "    'activation': ['relu', 'tanh','softmax']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X, y\n",
    "X = data[feature_sets['X3_X4']]  # Features\n",
    "y = data[['target_r', 'target_g', 'target_b']]  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING PARAMETERS:\n",
      "LAYER SIZES: (8, 4)\n",
      "ACTIVATION: relu\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 6ms/step - accuracy: 0.8796 - loss: 0.6622\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 513us/step - accuracy: 0.9179 - loss: 0.2086\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 605us/step - accuracy: 0.9416 - loss: 0.1031\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 445us/step - accuracy: 0.9945 - loss: 0.0401\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 453us/step - accuracy: 0.9964 - loss: 0.0219\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 483us/step - accuracy: 0.9945 - loss: 0.0187\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 451us/step - accuracy: 0.9964 - loss: 0.0162\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 442us/step - accuracy: 0.9964 - loss: 0.0166\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 460us/step - accuracy: 0.9982 - loss: 0.0135\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 472us/step - accuracy: 0.9964 - loss: 0.0161\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 520us/step - accuracy: 0.9982 - loss: 0.0116\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 503us/step - accuracy: 0.9964 - loss: 0.0125\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 500us/step - accuracy: 0.9964 - loss: 0.0126\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 488us/step - accuracy: 0.9964 - loss: 0.0119\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 957us/step - accuracy: 0.9945 - loss: 0.0118\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 519us/step - accuracy: 0.9982 - loss: 0.0113\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 422us/step - accuracy: 0.9964 - loss: 0.0112\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 424us/step - accuracy: 0.9964 - loss: 0.0119\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 430us/step - accuracy: 0.9982 - loss: 0.0122\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 437us/step - accuracy: 0.9982 - loss: 0.0104\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 581us/step - accuracy: 0.9982 - loss: 0.0108\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 440us/step - accuracy: 0.9982 - loss: 0.0097\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 455us/step - accuracy: 0.9982 - loss: 0.0141\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 421us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 428us/step - accuracy: 0.9982 - loss: 0.0122\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 417us/step - accuracy: 0.9982 - loss: 0.0082\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9964 - loss: 0.0094\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 421us/step - accuracy: 0.9964 - loss: 0.0078\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 382us/step - accuracy: 0.9945 - loss: 0.0091\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0099\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9964 - loss: 0.0085\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0114\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 712us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 448us/step - accuracy: 0.9945 - loss: 0.0067\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 427us/step - accuracy: 0.9982 - loss: 0.0118\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 437us/step - accuracy: 0.9964 - loss: 0.0047\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 440us/step - accuracy: 0.9982 - loss: 0.0089\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 427us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 386us/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0084\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 412us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 397us/step - accuracy: 0.9964 - loss: 0.0060\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9945 - loss: 0.0143\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0093\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0054\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0098\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 387us/step - accuracy: 0.9982 - loss: 0.0068\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 363us/step - accuracy: 0.9982 - loss: 0.0059\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (8, 4)\n",
      "ACTIVATION: tanh\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 6ms/step - accuracy: 0.8412 - loss: 0.5971\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 444us/step - accuracy: 0.9215 - loss: 0.2041\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9745 - loss: 0.0944\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 408us/step - accuracy: 0.9927 - loss: 0.0500\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9945 - loss: 0.0332\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 402us/step - accuracy: 0.9964 - loss: 0.0270\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9964 - loss: 0.0216\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 391us/step - accuracy: 0.9964 - loss: 0.0202\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 393us/step - accuracy: 0.9964 - loss: 0.0193\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9945 - loss: 0.0173\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 389us/step - accuracy: 0.9964 - loss: 0.0177\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 386us/step - accuracy: 0.9982 - loss: 0.0153\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 392us/step - accuracy: 0.9964 - loss: 0.0139\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 393us/step - accuracy: 0.9982 - loss: 0.0123\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9964 - loss: 0.0165\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 382us/step - accuracy: 0.9945 - loss: 0.0149\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0131\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 696us/step - accuracy: 0.9982 - loss: 0.0106\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 391us/step - accuracy: 0.9982 - loss: 0.0137\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0089\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 377us/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0108\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0063\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0089\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0102\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9964 - loss: 0.0099\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0068\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0097\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 380us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0090\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 353us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 852us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0089\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 384us/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0049\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 385us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0082\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 381us/step - accuracy: 0.9982 - loss: 0.0055\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0067\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (8, 4)\n",
      "ACTIVATION: softmax\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 5ms/step - accuracy: 0.6533 - loss: 0.8408\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 434us/step - accuracy: 0.8504 - loss: 0.5137\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 647us/step - accuracy: 0.8504 - loss: 0.4617\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 542us/step - accuracy: 0.8504 - loss: 0.4112\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 398us/step - accuracy: 0.8686 - loss: 0.3617\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 414us/step - accuracy: 0.9215 - loss: 0.3255\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 417us/step - accuracy: 0.9234 - loss: 0.2838\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 413us/step - accuracy: 0.9234 - loss: 0.1784\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 411us/step - accuracy: 0.9964 - loss: 0.1014\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 409us/step - accuracy: 0.9964 - loss: 0.0675\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 396us/step - accuracy: 0.9964 - loss: 0.0521\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 409us/step - accuracy: 0.9982 - loss: 0.0421\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 408us/step - accuracy: 0.9982 - loss: 0.0341\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 417us/step - accuracy: 0.9982 - loss: 0.0284\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9964 - loss: 0.0263\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 392us/step - accuracy: 0.9982 - loss: 0.0234\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 402us/step - accuracy: 0.9982 - loss: 0.0194\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9982 - loss: 0.0196\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 411us/step - accuracy: 0.9964 - loss: 0.0179\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 406us/step - accuracy: 0.9982 - loss: 0.0179\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 386us/step - accuracy: 0.9982 - loss: 0.0159\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 389us/step - accuracy: 0.9982 - loss: 0.0157\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 415us/step - accuracy: 0.9982 - loss: 0.0149\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 790us/step - accuracy: 0.9982 - loss: 0.0133\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 429us/step - accuracy: 0.9982 - loss: 0.0133\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0125\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 388us/step - accuracy: 0.9982 - loss: 0.0158\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 385us/step - accuracy: 0.9982 - loss: 0.0118\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 412us/step - accuracy: 0.9982 - loss: 0.0114\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 401us/step - accuracy: 0.9964 - loss: 0.0109\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9982 - loss: 0.0107\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 410us/step - accuracy: 0.9982 - loss: 0.0108\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 396us/step - accuracy: 0.9982 - loss: 0.0111\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9964 - loss: 0.0080\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9982 - loss: 0.0105\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 401us/step - accuracy: 0.9982 - loss: 0.0108\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9982 - loss: 0.0093\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 407us/step - accuracy: 0.9982 - loss: 0.0088\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 410us/step - accuracy: 0.9982 - loss: 0.0107\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 403us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 558us/step - accuracy: 0.9982 - loss: 0.0050\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 677us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 417us/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 407us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 401us/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 402us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 399us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 422us/step - accuracy: 0.9982 - loss: 0.0064\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (16, 8)\n",
      "ACTIVATION: relu\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 5ms/step - accuracy: 0.8175 - loss: 0.5861\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9106 - loss: 0.1966\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 391us/step - accuracy: 0.9252 - loss: 0.1082\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 390us/step - accuracy: 0.9909 - loss: 0.0850\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 399us/step - accuracy: 0.9927 - loss: 0.0670\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9945 - loss: 0.0533\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 787us/step - accuracy: 0.9927 - loss: 0.0482\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 412us/step - accuracy: 0.9945 - loss: 0.0408\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 391us/step - accuracy: 0.9964 - loss: 0.0328\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 417us/step - accuracy: 0.9964 - loss: 0.0288\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 385us/step - accuracy: 0.9964 - loss: 0.0301\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 412us/step - accuracy: 0.9964 - loss: 0.0242\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 413us/step - accuracy: 0.9982 - loss: 0.0210\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9982 - loss: 0.0196\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 418us/step - accuracy: 0.9964 - loss: 0.0189\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 385us/step - accuracy: 0.9982 - loss: 0.0153\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 414us/step - accuracy: 0.9982 - loss: 0.0175\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 400us/step - accuracy: 0.9982 - loss: 0.0167\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 394us/step - accuracy: 0.9945 - loss: 0.0206\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 392us/step - accuracy: 0.9964 - loss: 0.0157\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0091\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9982 - loss: 0.0145\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9982 - loss: 0.0150\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 403us/step - accuracy: 0.9982 - loss: 0.0142\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 381us/step - accuracy: 0.9982 - loss: 0.0121\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 394us/step - accuracy: 0.9982 - loss: 0.0108\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 771us/step - accuracy: 0.9982 - loss: 0.0118\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 470us/step - accuracy: 0.9982 - loss: 0.0117\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 414us/step - accuracy: 0.9982 - loss: 0.0111\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 424us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 421us/step - accuracy: 0.9982 - loss: 0.0077\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9982 - loss: 0.0097\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 428us/step - accuracy: 0.9982 - loss: 0.0107\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 434us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 443us/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 424us/step - accuracy: 0.9964 - loss: 0.0122\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 428us/step - accuracy: 0.9982 - loss: 0.0098\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 420us/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 427us/step - accuracy: 0.9982 - loss: 0.0115\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 429us/step - accuracy: 0.9982 - loss: 0.0067\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 444us/step - accuracy: 0.9945 - loss: 0.0170\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 414us/step - accuracy: 0.9964 - loss: 0.0113\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 432us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 885us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 445us/step - accuracy: 0.9982 - loss: 0.0133\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 418us/step - accuracy: 0.9982 - loss: 0.0067\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 422us/step - accuracy: 0.9982 - loss: 0.0038\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 432us/step - accuracy: 0.9982 - loss: 0.0048\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 409us/step - accuracy: 0.9982 - loss: 0.0033\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 420us/step - accuracy: 0.9945 - loss: 0.0078\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (16, 8)\n",
      "ACTIVATION: tanh\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 6ms/step - accuracy: 0.8996 - loss: 0.3427\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 438us/step - accuracy: 0.9708 - loss: 0.0815\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 437us/step - accuracy: 0.9945 - loss: 0.0303\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 415us/step - accuracy: 0.9964 - loss: 0.0190\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 423us/step - accuracy: 0.9982 - loss: 0.0157\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9982 - loss: 0.0145\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 410us/step - accuracy: 0.9982 - loss: 0.0156\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 392us/step - accuracy: 0.9964 - loss: 0.0156\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 772us/step - accuracy: 0.9964 - loss: 0.0156\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 491us/step - accuracy: 0.9945 - loss: 0.0142\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 412us/step - accuracy: 0.9927 - loss: 0.0180\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 399us/step - accuracy: 0.9982 - loss: 0.0112\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 416us/step - accuracy: 0.9982 - loss: 0.0099\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 437us/step - accuracy: 0.9982 - loss: 0.0070\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9982 - loss: 0.0090\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 422us/step - accuracy: 0.9982 - loss: 0.0112\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 384us/step - accuracy: 0.9982 - loss: 0.0093\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 392us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 381us/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 369us/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 363us/step - accuracy: 0.9982 - loss: 0.0090\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 390us/step - accuracy: 0.9964 - loss: 0.0070\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9982 - loss: 0.0093\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 380us/step - accuracy: 0.9982 - loss: 0.0082\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 496us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 391us/step - accuracy: 0.9982 - loss: 0.0091\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 384us/step - accuracy: 0.9982 - loss: 0.0093\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 752us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 460us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 422us/step - accuracy: 0.9982 - loss: 0.0084\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 424us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 426us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 424us/step - accuracy: 0.9982 - loss: 0.0117\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 427us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9982 - loss: 0.0070\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 419us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 404us/step - accuracy: 0.9964 - loss: 0.0065\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 427us/step - accuracy: 0.9982 - loss: 0.0090\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 428us/step - accuracy: 0.9982 - loss: 0.0069\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 433us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 426us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 411us/step - accuracy: 0.9982 - loss: 0.0057\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9982 - loss: 0.0064\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 403us/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 402us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 736us/step - accuracy: 0.9982 - loss: 0.0077\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 509us/step - accuracy: 0.9982 - loss: 0.0062\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (16, 8)\n",
      "ACTIVATION: softmax\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 5ms/step - accuracy: 0.8376 - loss: 0.7116\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 418us/step - accuracy: 0.8504 - loss: 0.5252\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 388us/step - accuracy: 0.8504 - loss: 0.4894\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 421us/step - accuracy: 0.8504 - loss: 0.4050\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 412us/step - accuracy: 0.8978 - loss: 0.2782\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 429us/step - accuracy: 0.9617 - loss: 0.1509\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 435us/step - accuracy: 0.9927 - loss: 0.0820\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 420us/step - accuracy: 0.9964 - loss: 0.0556\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 399us/step - accuracy: 0.9964 - loss: 0.0433\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 412us/step - accuracy: 0.9982 - loss: 0.0345\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9964 - loss: 0.0293\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9964 - loss: 0.0248\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0213\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 357us/step - accuracy: 0.9964 - loss: 0.0208\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0186\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 713us/step - accuracy: 0.9964 - loss: 0.0171\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0132\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0148\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 357us/step - accuracy: 0.9982 - loss: 0.0142\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0140\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0139\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0119\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0105\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 356us/step - accuracy: 0.9982 - loss: 0.0117\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 358us/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0099\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0091\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9982 - loss: 0.0122\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9982 - loss: 0.0100\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 356us/step - accuracy: 0.9982 - loss: 0.0095\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 355us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 620us/step - accuracy: 0.9964 - loss: 0.0096\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 472us/step - accuracy: 0.9982 - loss: 0.0088\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0100\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 411us/step - accuracy: 0.9982 - loss: 0.0070\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 389us/step - accuracy: 0.9927 - loss: 0.0099\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 389us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 436us/step - accuracy: 0.9982 - loss: 0.0064\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 440us/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 425us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 429us/step - accuracy: 0.9982 - loss: 0.0070\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 450us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 418us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 411us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (32, 16)\n",
      "ACTIVATION: relu\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 6ms/step - accuracy: 0.8869 - loss: 0.4007\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 451us/step - accuracy: 0.9927 - loss: 0.0483\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 402us/step - accuracy: 0.9927 - loss: 0.0236\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 425us/step - accuracy: 0.9927 - loss: 0.0172\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 441us/step - accuracy: 0.9945 - loss: 0.0233\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 431us/step - accuracy: 0.9982 - loss: 0.0089\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 436us/step - accuracy: 0.9964 - loss: 0.0173\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 408us/step - accuracy: 0.9945 - loss: 0.0162\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 405us/step - accuracy: 0.9964 - loss: 0.0173\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0130\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9945 - loss: 0.0189\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 359us/step - accuracy: 0.9982 - loss: 0.0114\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0115\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9982 - loss: 0.0098\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 363us/step - accuracy: 0.9945 - loss: 0.0201\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9945 - loss: 0.0285\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9964 - loss: 0.0120\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0091\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 718us/step - accuracy: 0.9964 - loss: 0.0149\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 410us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0059\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0112\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 353us/step - accuracy: 0.9982 - loss: 0.0037\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 353us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 349us/step - accuracy: 0.9982 - loss: 0.0089\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 356us/step - accuracy: 0.9945 - loss: 0.0121\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0123\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 353us/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 352us/step - accuracy: 0.9982 - loss: 0.0057\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 350us/step - accuracy: 0.9982 - loss: 0.0109\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 362us/step - accuracy: 0.9982 - loss: 0.0068\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 355us/step - accuracy: 0.9982 - loss: 0.0062\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 355us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 348us/step - accuracy: 0.9982 - loss: 0.0029\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 353us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 350us/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0095\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 354us/step - accuracy: 0.9982 - loss: 0.0044\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 717us/step - accuracy: 0.9982 - loss: 0.0084\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9982 - loss: 0.0084\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 357us/step - accuracy: 0.9982 - loss: 0.0057\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 356us/step - accuracy: 0.9982 - loss: 0.0055\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 352us/step - accuracy: 0.9982 - loss: 0.0053\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 369us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 358us/step - accuracy: 0.9982 - loss: 0.0031\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 348us/step - accuracy: 0.9964 - loss: 0.0081\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 350us/step - accuracy: 0.9982 - loss: 0.0058\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (32, 16)\n",
      "ACTIVATION: tanh\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 6ms/step - accuracy: 0.9197 - loss: 0.2841\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 433us/step - accuracy: 0.9945 - loss: 0.0250\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9945 - loss: 0.0182\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9909 - loss: 0.0255\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9909 - loss: 0.0362\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9927 - loss: 0.0174\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9964 - loss: 0.0160\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 729us/step - accuracy: 0.9945 - loss: 0.0187\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 394us/step - accuracy: 0.9982 - loss: 0.0121\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 357us/step - accuracy: 0.9964 - loss: 0.0152\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 369us/step - accuracy: 0.9982 - loss: 0.0122\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0102\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 356us/step - accuracy: 0.9982 - loss: 0.0084\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 345us/step - accuracy: 0.9945 - loss: 0.0126\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 353us/step - accuracy: 0.9945 - loss: 0.0145\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 348us/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0110\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 354us/step - accuracy: 0.9982 - loss: 0.0084\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 354us/step - accuracy: 0.9964 - loss: 0.0075\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0108\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9982 - loss: 0.0102\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 381us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 389us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 419us/step - accuracy: 0.9982 - loss: 0.0066\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 740us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 603us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 431us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 426us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0083\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 389us/step - accuracy: 0.9945 - loss: 0.0127\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9964 - loss: 0.0175\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9964 - loss: 0.0110\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 362us/step - accuracy: 0.9891 - loss: 0.0273\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0083\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 455us/step - accuracy: 0.9982 - loss: 0.0069\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 385us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 385us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9982 - loss: 0.0056\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 390us/step - accuracy: 0.9982 - loss: 0.0118\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 359us/step - accuracy: 0.9964 - loss: 0.0088\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9982 - loss: 0.0100\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 714us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 391us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 367us/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (32, 16)\n",
      "ACTIVATION: softmax\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 5ms/step - accuracy: 0.8120 - loss: 0.7230\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 400us/step - accuracy: 0.8504 - loss: 0.5195\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.8504 - loss: 0.4709\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.8686 - loss: 0.3804\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9215 - loss: 0.3050\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9252 - loss: 0.2411\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9471 - loss: 0.1248\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9964 - loss: 0.0529\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9964 - loss: 0.0341\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9964 - loss: 0.0269\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0214\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0179\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 703us/step - accuracy: 0.9964 - loss: 0.0169\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 397us/step - accuracy: 0.9982 - loss: 0.0163\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0130\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9982 - loss: 0.0129\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0114\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 361us/step - accuracy: 0.9982 - loss: 0.0117\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9982 - loss: 0.0112\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0097\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0101\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 362us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 361us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 363us/step - accuracy: 0.9964 - loss: 0.0092\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0089\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 361us/step - accuracy: 0.9982 - loss: 0.0056\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 714us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 390us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0064\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0068\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0046\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0076\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0045\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9982 - loss: 0.0067\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0042\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0057\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 362us/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0060\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 385us/step - accuracy: 0.9964 - loss: 0.0072\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 395us/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 386us/step - accuracy: 0.9982 - loss: 0.0069\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (64, 32)\n",
      "ACTIVATION: relu\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 5ms/step - accuracy: 0.9124 - loss: 0.3430\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 420us/step - accuracy: 0.9945 - loss: 0.0298\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9964 - loss: 0.0217\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 417us/step - accuracy: 0.9854 - loss: 0.0395\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 433us/step - accuracy: 0.9945 - loss: 0.0166\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 426us/step - accuracy: 0.9909 - loss: 0.0299\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 419us/step - accuracy: 0.9945 - loss: 0.0171\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 428us/step - accuracy: 0.9982 - loss: 0.0128\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 429us/step - accuracy: 0.9964 - loss: 0.0204\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 467us/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 456us/step - accuracy: 0.9964 - loss: 0.0147\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 415us/step - accuracy: 0.9982 - loss: 0.0137\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 410us/step - accuracy: 0.9982 - loss: 0.0102\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 434us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 431us/step - accuracy: 0.9964 - loss: 0.0170\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 840us/step - accuracy: 0.9982 - loss: 0.0094\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 502us/step - accuracy: 0.9945 - loss: 0.0082\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 426us/step - accuracy: 0.9982 - loss: 0.0144\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 439us/step - accuracy: 0.9982 - loss: 0.0098\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 430us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 445us/step - accuracy: 0.9982 - loss: 0.0067\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 437us/step - accuracy: 0.9982 - loss: 0.0122\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 425us/step - accuracy: 0.9945 - loss: 0.0126\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 426us/step - accuracy: 0.9726 - loss: 0.0843\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 429us/step - accuracy: 0.9982 - loss: 0.0129\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 415us/step - accuracy: 0.9982 - loss: 0.0114\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 401us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 413us/step - accuracy: 0.9982 - loss: 0.0064\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 411us/step - accuracy: 0.9982 - loss: 0.0115\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 427us/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 392us/step - accuracy: 0.9982 - loss: 0.0069\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9982 - loss: 0.0077\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 397us/step - accuracy: 0.9982 - loss: 0.0063\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 391us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 380us/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 388us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 749us/step - accuracy: 0.9982 - loss: 0.0062\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 406us/step - accuracy: 0.9982 - loss: 0.0069\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 384us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9945 - loss: 0.0145\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 386us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 386us/step - accuracy: 0.9982 - loss: 0.0067\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 382us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9982 - loss: 0.0054\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9982 - loss: 0.0049\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 369us/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 361us/step - accuracy: 0.9982 - loss: 0.0058\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (64, 32)\n",
      "ACTIVATION: tanh\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 5ms/step - accuracy: 0.9416 - loss: 0.1628\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 438us/step - accuracy: 0.9927 - loss: 0.0238\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 381us/step - accuracy: 0.9891 - loss: 0.0237\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 706us/step - accuracy: 0.9964 - loss: 0.0151\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9945 - loss: 0.0165\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9945 - loss: 0.0142\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9927 - loss: 0.0245\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9909 - loss: 0.0239\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 365us/step - accuracy: 0.9836 - loss: 0.0832\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 360us/step - accuracy: 0.9964 - loss: 0.0161\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0113\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9945 - loss: 0.0155\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9945 - loss: 0.0188\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 354us/step - accuracy: 0.9982 - loss: 0.0115\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 363us/step - accuracy: 0.9964 - loss: 0.0100\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 358us/step - accuracy: 0.9927 - loss: 0.0147\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 359us/step - accuracy: 0.9945 - loss: 0.0305\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 382us/step - accuracy: 0.9964 - loss: 0.0092\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 361us/step - accuracy: 0.9964 - loss: 0.0124\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 369us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 362us/step - accuracy: 0.9982 - loss: 0.0118\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 578us/step - accuracy: 0.9982 - loss: 0.0093\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 484us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0097\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 355us/step - accuracy: 0.9982 - loss: 0.0114\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 359us/step - accuracy: 0.9945 - loss: 0.0261\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9982 - loss: 0.0107\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 358us/step - accuracy: 0.9982 - loss: 0.0101\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 357us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 370us/step - accuracy: 0.9982 - loss: 0.0088\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 357us/step - accuracy: 0.9982 - loss: 0.0083\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 357us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 358us/step - accuracy: 0.9982 - loss: 0.0074\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 359us/step - accuracy: 0.9982 - loss: 0.0104\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 356us/step - accuracy: 0.9982 - loss: 0.0094\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0069\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 355us/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 701us/step - accuracy: 0.9982 - loss: 0.0085\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 402us/step - accuracy: 0.9982 - loss: 0.0073\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9964 - loss: 0.0134\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9964 - loss: 0.0280\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9964 - loss: 0.0148\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9964 - loss: 0.0234\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0087\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "====================================\n",
      "USING PARAMETERS:\n",
      "LAYER SIZES: (64, 32)\n",
      "ACTIVATION: softmax\n",
      "====================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - 5ms/step - accuracy: 0.8504 - loss: 0.7336\n",
      "Epoch 2/50\n",
      "55/55 - 0s - 389us/step - accuracy: 0.8504 - loss: 0.5220\n",
      "Epoch 3/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.8504 - loss: 0.4669\n",
      "Epoch 4/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.8595 - loss: 0.3804\n",
      "Epoch 5/50\n",
      "55/55 - 0s - 380us/step - accuracy: 0.9215 - loss: 0.3045\n",
      "Epoch 6/50\n",
      "55/55 - 0s - 369us/step - accuracy: 0.9252 - loss: 0.2592\n",
      "Epoch 7/50\n",
      "55/55 - 0s - 378us/step - accuracy: 0.9270 - loss: 0.1677\n",
      "Epoch 8/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9781 - loss: 0.0872\n",
      "Epoch 9/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0524\n",
      "Epoch 10/50\n",
      "55/55 - 0s - 387us/step - accuracy: 0.9982 - loss: 0.0368\n",
      "Epoch 11/50\n",
      "55/55 - 0s - 713us/step - accuracy: 0.9982 - loss: 0.0278\n",
      "Epoch 12/50\n",
      "55/55 - 0s - 395us/step - accuracy: 0.9982 - loss: 0.0228\n",
      "Epoch 13/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9982 - loss: 0.0201\n",
      "Epoch 14/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0189\n",
      "Epoch 15/50\n",
      "55/55 - 0s - 381us/step - accuracy: 0.9982 - loss: 0.0158\n",
      "Epoch 16/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9964 - loss: 0.0155\n",
      "Epoch 17/50\n",
      "55/55 - 0s - 364us/step - accuracy: 0.9982 - loss: 0.0119\n",
      "Epoch 18/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0124\n",
      "Epoch 19/50\n",
      "55/55 - 0s - 366us/step - accuracy: 0.9982 - loss: 0.0104\n",
      "Epoch 20/50\n",
      "55/55 - 0s - 362us/step - accuracy: 0.9982 - loss: 0.0124\n",
      "Epoch 21/50\n",
      "55/55 - 0s - 380us/step - accuracy: 0.9982 - loss: 0.0107\n",
      "Epoch 22/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 23/50\n",
      "55/55 - 0s - 388us/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 24/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9964 - loss: 0.0093\n",
      "Epoch 25/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0133\n",
      "Epoch 26/50\n",
      "55/55 - 0s - 374us/step - accuracy: 0.9982 - loss: 0.0105\n",
      "Epoch 27/50\n",
      "55/55 - 0s - 375us/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 28/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9982 - loss: 0.0094\n",
      "Epoch 29/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0080\n",
      "Epoch 30/50\n",
      "55/55 - 0s - 372us/step - accuracy: 0.9982 - loss: 0.0082\n",
      "Epoch 31/50\n",
      "55/55 - 0s - 361us/step - accuracy: 0.9982 - loss: 0.0091\n",
      "Epoch 32/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 33/50\n",
      "55/55 - 0s - 379us/step - accuracy: 0.9982 - loss: 0.0096\n",
      "Epoch 34/50\n",
      "55/55 - 0s - 715us/step - accuracy: 0.9982 - loss: 0.0064\n",
      "Epoch 35/50\n",
      "55/55 - 0s - 401us/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 36/50\n",
      "55/55 - 0s - 377us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 37/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 38/50\n",
      "55/55 - 0s - 375us/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 39/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0086\n",
      "Epoch 40/50\n",
      "55/55 - 0s - 383us/step - accuracy: 0.9982 - loss: 0.0064\n",
      "Epoch 41/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0058\n",
      "Epoch 42/50\n",
      "55/55 - 0s - 371us/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 43/50\n",
      "55/55 - 0s - 368us/step - accuracy: 0.9964 - loss: 0.0093\n",
      "Epoch 44/50\n",
      "55/55 - 0s - 364us/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 45/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0058\n",
      "Epoch 46/50\n",
      "55/55 - 0s - 382us/step - accuracy: 0.9982 - loss: 0.0056\n",
      "Epoch 47/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 48/50\n",
      "55/55 - 0s - 373us/step - accuracy: 0.9982 - loss: 0.0051\n",
      "Epoch 49/50\n",
      "55/55 - 0s - 384us/step - accuracy: 0.9982 - loss: 0.0057\n",
      "Epoch 50/50\n",
      "55/55 - 0s - 376us/step - accuracy: 0.9982 - loss: 0.0045\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Store the results\n",
    "results = {}\n",
    "\n",
    "# Initialize and train the tensorflow neural network\n",
    "for hidden_layer_sizes in nn_params['hidden_layer_sizes']:\n",
    "    for activation in nn_params['activation']:\n",
    "        clear_session()  # Clear the previous model and configurations\n",
    "\n",
    "        print(f\"USING PARAMETERS:\\nLAYER SIZES: {hidden_layer_sizes}\\nACTIVATION: {activation}\")\n",
    "        print(\"====================================\")\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden_layer_sizes[0], input_dim=X.shape[1], activation=activation))\n",
    "        model.add(Dense(hidden_layer_sizes[1], activation=activation))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=2)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        print(\"====================================\")\n",
    "        results[(hidden_layer_sizes, activation)] = y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nueral network for all feature sets(1-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with features: ['X3', 'X4']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1797 - loss: 1.0970 - val_accuracy: 0.8727 - val_loss: 1.0037\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.9608 - val_accuracy: 0.9000 - val_loss: 0.8865\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.8301 - val_accuracy: 0.8909 - val_loss: 0.7657\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.7046 - val_accuracy: 0.8909 - val_loss: 0.6407\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.5824 - val_accuracy: 0.8909 - val_loss: 0.5289\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.4699 - val_accuracy: 0.8909 - val_loss: 0.4354\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9373 - loss: 0.3480 - val_accuracy: 0.8909 - val_loss: 0.3635\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.3318 - val_accuracy: 0.8909 - val_loss: 0.3013\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2400 - val_accuracy: 0.8909 - val_loss: 0.2542\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9388 - loss: 0.1855 - val_accuracy: 0.8909 - val_loss: 0.2081\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.1750 - val_accuracy: 0.8909 - val_loss: 0.1649\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1340 - val_accuracy: 0.9818 - val_loss: 0.1348\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.1191 - val_accuracy: 0.9909 - val_loss: 0.1085\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0911 - val_accuracy: 0.9909 - val_loss: 0.0901\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0785 - val_accuracy: 0.9909 - val_loss: 0.0754\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0635 - val_accuracy: 0.9909 - val_loss: 0.0627\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0443 - val_accuracy: 0.9909 - val_loss: 0.0543\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0447 - val_accuracy: 0.9909 - val_loss: 0.0451\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0387 - val_accuracy: 0.9909 - val_loss: 0.0403\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0412 - val_accuracy: 0.9909 - val_loss: 0.0345\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0382 - val_accuracy: 0.9909 - val_loss: 0.0311\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0300 - val_accuracy: 0.9909 - val_loss: 0.0286\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0250 - val_accuracy: 0.9909 - val_loss: 0.0269\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0221 - val_accuracy: 0.9909 - val_loss: 0.0236\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0237 - val_accuracy: 0.9909 - val_loss: 0.0212\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9887 - loss: 0.0308 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0197 - val_accuracy: 0.9909 - val_loss: 0.0180\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0198 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9884 - loss: 0.0353 - val_accuracy: 1.0000 - val_loss: 0.0151\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9840 - loss: 0.0378 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0117\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0278 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9965 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 47/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0213 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 49/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 50/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 51/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 52/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 53/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 54/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9994 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 55/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 56/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 57/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 58/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 59/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.9982 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 60/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 61/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 62/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 63/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 64/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 65/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 66/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 67/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.9997 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 68/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 70/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 71/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 72/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 73/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 76/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 77/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 78/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.9978 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 80/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 81/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 82/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9992 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 83/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.9985 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 85/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 86/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 88/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 89/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 9.4350e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 9.2604e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 9.3073e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 9.0203e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 8.7887e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 8.7882e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 8.1806e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 7.4967e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 7.4423e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 7.7315e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Confusion Matrix for X3_X4:\n",
      "[[119   0   0]\n",
      " [  0   7   0]\n",
      " [  0   0  11]]\n",
      "Test Accuracy for X3_X4: 1.0, Test Loss: 0.004880738910287619\n",
      "Training model with features: ['X3', 'X5']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2212 - loss: 1.0901 - val_accuracy: 0.7636 - val_loss: 0.9858\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8442 - loss: 0.9281 - val_accuracy: 0.8818 - val_loss: 0.8615\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8702 - loss: 0.8205 - val_accuracy: 0.8636 - val_loss: 0.7606\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8434 - loss: 0.7423 - val_accuracy: 0.8727 - val_loss: 0.6840\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8580 - loss: 0.6817 - val_accuracy: 0.8727 - val_loss: 0.6358\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8766 - loss: 0.6012 - val_accuracy: 0.8818 - val_loss: 0.5972\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8716 - loss: 0.5640 - val_accuracy: 0.8818 - val_loss: 0.5641\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.5104 - val_accuracy: 0.8818 - val_loss: 0.5291\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.4739 - val_accuracy: 0.8818 - val_loss: 0.4962\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.8704 - loss: 0.4677 - val_accuracy: 0.8818 - val_loss: 0.4629\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.8997 - loss: 0.3944 - val_accuracy: 0.8818 - val_loss: 0.4328\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.8968 - loss: 0.3552 - val_accuracy: 0.8818 - val_loss: 0.4062\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8879 - loss: 0.3626 - val_accuracy: 0.8818 - val_loss: 0.3789\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9080 - loss: 0.3162 - val_accuracy: 0.8818 - val_loss: 0.3575\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.3245 - val_accuracy: 0.8818 - val_loss: 0.3385\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2794 - val_accuracy: 0.8818 - val_loss: 0.3227\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2366 - val_accuracy: 0.8818 - val_loss: 0.3068\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2537 - val_accuracy: 0.8818 - val_loss: 0.2931\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.9121 - loss: 0.2434 - val_accuracy: 0.8818 - val_loss: 0.2833\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9175 - loss: 0.2260 - val_accuracy: 0.8818 - val_loss: 0.2734\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2304 - val_accuracy: 0.8818 - val_loss: 0.2627\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2245 - val_accuracy: 0.8818 - val_loss: 0.2553\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.9226 - loss: 0.2103 - val_accuracy: 0.8818 - val_loss: 0.2513\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9331 - loss: 0.1795 - val_accuracy: 0.8818 - val_loss: 0.2492\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.2543 - val_accuracy: 0.8818 - val_loss: 0.2382\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8949 - loss: 0.2245 - val_accuracy: 0.8818 - val_loss: 0.2371\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2259 - val_accuracy: 0.8818 - val_loss: 0.2356\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9035 - loss: 0.2224 - val_accuracy: 0.8818 - val_loss: 0.2276\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2141 - val_accuracy: 0.8818 - val_loss: 0.2259\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.1989 - val_accuracy: 0.8818 - val_loss: 0.2233\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.8972 - loss: 0.1979 - val_accuracy: 0.8818 - val_loss: 0.2210\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9270 - loss: 0.1884 - val_accuracy: 0.8818 - val_loss: 0.2151\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2100 - val_accuracy: 0.8909 - val_loss: 0.2130\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2045 - val_accuracy: 0.8818 - val_loss: 0.2150\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.1773 - val_accuracy: 0.9545 - val_loss: 0.2066\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9290 - loss: 0.1518 - val_accuracy: 0.8818 - val_loss: 0.2052\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9091 - loss: 0.1771 - val_accuracy: 0.9545 - val_loss: 0.2021\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9292 - loss: 0.1907 - val_accuracy: 0.9000 - val_loss: 0.2056\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9345 - loss: 0.1492 - val_accuracy: 0.9000 - val_loss: 0.2006\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9346 - loss: 0.1614 - val_accuracy: 0.9455 - val_loss: 0.1928\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9240 - loss: 0.2025 - val_accuracy: 0.9455 - val_loss: 0.1963\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9264 - loss: 0.1788 - val_accuracy: 0.9545 - val_loss: 0.1941\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9450 - loss: 0.1754 - val_accuracy: 0.9455 - val_loss: 0.1917\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.9343 - loss: 0.1751 - val_accuracy: 0.9455 - val_loss: 0.1897\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.1718 - val_accuracy: 0.9455 - val_loss: 0.1872\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1684 - val_accuracy: 0.9455 - val_loss: 0.1840\n",
      "Epoch 47/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8998 - loss: 0.2114 - val_accuracy: 0.9455 - val_loss: 0.1864\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9329 - loss: 0.1554 - val_accuracy: 0.9455 - val_loss: 0.1824\n",
      "Epoch 49/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9468 - loss: 0.1698 - val_accuracy: 0.9364 - val_loss: 0.1774\n",
      "Epoch 50/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9424 - loss: 0.1491 - val_accuracy: 0.9545 - val_loss: 0.1815\n",
      "Epoch 51/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1514 - val_accuracy: 0.9273 - val_loss: 0.1761\n",
      "Epoch 52/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9530 - loss: 0.1349 - val_accuracy: 0.9545 - val_loss: 0.1731\n",
      "Epoch 53/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.1739 - val_accuracy: 0.9364 - val_loss: 0.1662\n",
      "Epoch 54/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9341 - loss: 0.1700 - val_accuracy: 0.9545 - val_loss: 0.1708\n",
      "Epoch 55/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1664 - val_accuracy: 0.9545 - val_loss: 0.1720\n",
      "Epoch 56/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.9503 - loss: 0.1410 - val_accuracy: 0.9273 - val_loss: 0.1672\n",
      "Epoch 57/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.9470 - loss: 0.1532 - val_accuracy: 0.9545 - val_loss: 0.1653\n",
      "Epoch 58/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9460 - loss: 0.1514 - val_accuracy: 0.9364 - val_loss: 0.1647\n",
      "Epoch 59/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1504 - val_accuracy: 0.9636 - val_loss: 0.1643\n",
      "Epoch 60/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.1518 - val_accuracy: 0.9273 - val_loss: 0.1611\n",
      "Epoch 61/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1531 - val_accuracy: 0.9364 - val_loss: 0.1566\n",
      "Epoch 62/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1447 - val_accuracy: 0.9636 - val_loss: 0.1619\n",
      "Epoch 63/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1547 - val_accuracy: 0.9364 - val_loss: 0.1553\n",
      "Epoch 64/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1325 - val_accuracy: 0.9364 - val_loss: 0.1503\n",
      "Epoch 65/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1313 - val_accuracy: 0.9455 - val_loss: 0.1546\n",
      "Epoch 66/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1230 - val_accuracy: 0.9455 - val_loss: 0.1560\n",
      "Epoch 67/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.1225 - val_accuracy: 0.9455 - val_loss: 0.1526\n",
      "Epoch 68/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1278 - val_accuracy: 0.9455 - val_loss: 0.1459\n",
      "Epoch 69/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1478 - val_accuracy: 0.9545 - val_loss: 0.1504\n",
      "Epoch 70/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1384 - val_accuracy: 0.9364 - val_loss: 0.1457\n",
      "Epoch 71/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.1457 - val_accuracy: 0.9455 - val_loss: 0.1498\n",
      "Epoch 72/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.1285 - val_accuracy: 0.9364 - val_loss: 0.1482\n",
      "Epoch 73/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1374 - val_accuracy: 0.9545 - val_loss: 0.1444\n",
      "Epoch 74/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9342 - loss: 0.1262 - val_accuracy: 0.9455 - val_loss: 0.1414\n",
      "Epoch 75/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1305 - val_accuracy: 0.9455 - val_loss: 0.1439\n",
      "Epoch 76/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1205 - val_accuracy: 0.9455 - val_loss: 0.1418\n",
      "Epoch 77/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1389 - val_accuracy: 0.9455 - val_loss: 0.1387\n",
      "Epoch 78/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1409 - val_accuracy: 0.9455 - val_loss: 0.1400\n",
      "Epoch 79/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1275 - val_accuracy: 0.9455 - val_loss: 0.1369\n",
      "Epoch 80/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1512 - val_accuracy: 0.9364 - val_loss: 0.1354\n",
      "Epoch 81/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1413 - val_accuracy: 0.9455 - val_loss: 0.1373\n",
      "Epoch 82/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1075 - val_accuracy: 0.9455 - val_loss: 0.1378\n",
      "Epoch 83/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1214 - val_accuracy: 0.9455 - val_loss: 0.1338\n",
      "Epoch 84/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.1367 - val_accuracy: 0.9455 - val_loss: 0.1345\n",
      "Epoch 85/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1159 - val_accuracy: 0.9455 - val_loss: 0.1328\n",
      "Epoch 86/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1193 - val_accuracy: 0.9545 - val_loss: 0.1328\n",
      "Epoch 87/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1179 - val_accuracy: 0.9455 - val_loss: 0.1338\n",
      "Epoch 88/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.1062 - val_accuracy: 0.9364 - val_loss: 0.1310\n",
      "Epoch 89/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1097 - val_accuracy: 0.9545 - val_loss: 0.1319\n",
      "Epoch 90/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1136 - val_accuracy: 0.9455 - val_loss: 0.1289\n",
      "Epoch 91/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.1468 - val_accuracy: 0.9455 - val_loss: 0.1318\n",
      "Epoch 92/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1226 - val_accuracy: 0.9455 - val_loss: 0.1276\n",
      "Epoch 93/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1292 - val_accuracy: 0.9455 - val_loss: 0.1270\n",
      "Epoch 94/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1246 - val_accuracy: 0.9364 - val_loss: 0.1341\n",
      "Epoch 95/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9602 - loss: 0.1129 - val_accuracy: 0.9455 - val_loss: 0.1247\n",
      "Epoch 96/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1329 - val_accuracy: 0.9455 - val_loss: 0.1257\n",
      "Epoch 97/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1303 - val_accuracy: 0.9455 - val_loss: 0.1260\n",
      "Epoch 98/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1181 - val_accuracy: 0.9455 - val_loss: 0.1303\n",
      "Epoch 99/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1096 - val_accuracy: 0.9455 - val_loss: 0.1251\n",
      "Epoch 100/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.1093 - val_accuracy: 0.9455 - val_loss: 0.1225\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Confusion Matrix for X3_X5:\n",
      "[[117   0   2]\n",
      " [  1   6   0]\n",
      " [  0   0  11]]\n",
      "Test Accuracy for X3_X5: 0.9781021897810219, Test Loss: 0.0938430055975914\n",
      "Training model with features: ['X3', 'X4', 'X5']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5123 - loss: 1.0580 - val_accuracy: 0.8636 - val_loss: 0.8866\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8620 - loss: 0.8322 - val_accuracy: 0.8455 - val_loss: 0.7120\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8799 - loss: 0.6435 - val_accuracy: 0.8455 - val_loss: 0.5727\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.5081 - val_accuracy: 0.8727 - val_loss: 0.4676\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.9084 - loss: 0.4095 - val_accuracy: 0.8818 - val_loss: 0.3914\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.2885 - val_accuracy: 0.8818 - val_loss: 0.3317\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.8952 - loss: 0.3138 - val_accuracy: 0.8818 - val_loss: 0.2747\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9178 - loss: 0.2299 - val_accuracy: 0.8818 - val_loss: 0.2296\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9009 - loss: 0.2072 - val_accuracy: 0.8818 - val_loss: 0.1907\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.8932 - loss: 0.2052 - val_accuracy: 0.9636 - val_loss: 0.1575\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9781 - loss: 0.1341 - val_accuracy: 0.9909 - val_loss: 0.1307\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9840 - loss: 0.1163 - val_accuracy: 0.9909 - val_loss: 0.1096\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0900 - val_accuracy: 0.9909 - val_loss: 0.0943\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0670 - val_accuracy: 0.9909 - val_loss: 0.0799\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9957 - loss: 0.0673 - val_accuracy: 0.9909 - val_loss: 0.0704\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9888 - loss: 0.0720 - val_accuracy: 0.9909 - val_loss: 0.0602\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9920 - loss: 0.0569 - val_accuracy: 0.9909 - val_loss: 0.0545\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.9955 - loss: 0.0474 - val_accuracy: 0.9909 - val_loss: 0.0489\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9917 - loss: 0.0471 - val_accuracy: 0.9909 - val_loss: 0.0449\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9887 - loss: 0.0450 - val_accuracy: 0.9909 - val_loss: 0.0419\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0358 - val_accuracy: 0.9909 - val_loss: 0.0380\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.9955 - loss: 0.0303 - val_accuracy: 0.9909 - val_loss: 0.0357\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9918 - loss: 0.0365 - val_accuracy: 0.9909 - val_loss: 0.0336\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9943 - loss: 0.0275 - val_accuracy: 0.9909 - val_loss: 0.0320\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0246 - val_accuracy: 0.9909 - val_loss: 0.0304\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9902 - loss: 0.0322 - val_accuracy: 0.9909 - val_loss: 0.0287\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9942 - loss: 0.0230 - val_accuracy: 0.9909 - val_loss: 0.0278\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9932 - loss: 0.0264 - val_accuracy: 0.9909 - val_loss: 0.0274\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.9921 - loss: 0.0267 - val_accuracy: 0.9909 - val_loss: 0.0259\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9967 - loss: 0.0158 - val_accuracy: 0.9909 - val_loss: 0.0261\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9874 - loss: 0.0236 - val_accuracy: 0.9909 - val_loss: 0.0253\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9942 - loss: 0.0179 - val_accuracy: 0.9909 - val_loss: 0.0248\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9920 - loss: 0.0225 - val_accuracy: 0.9909 - val_loss: 0.0246\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9936 - loss: 0.0183 - val_accuracy: 0.9909 - val_loss: 0.0244\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.9992 - loss: 0.0122 - val_accuracy: 0.9909 - val_loss: 0.0251\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9975 - loss: 0.0133 - val_accuracy: 0.9909 - val_loss: 0.0234\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9930 - loss: 0.0182 - val_accuracy: 0.9909 - val_loss: 0.0231\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.9983 - loss: 0.0132 - val_accuracy: 0.9909 - val_loss: 0.0244\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.9909 - val_loss: 0.0245\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0132 - val_accuracy: 0.9909 - val_loss: 0.0235\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0105 - val_accuracy: 0.9909 - val_loss: 0.0238\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9900 - loss: 0.0189 - val_accuracy: 0.9909 - val_loss: 0.0240\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 0.9909 - val_loss: 0.0256\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9938 - loss: 0.0150 - val_accuracy: 0.9909 - val_loss: 0.0245\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9931 - loss: 0.0137 - val_accuracy: 0.9909 - val_loss: 0.0250\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0099 - val_accuracy: 0.9909 - val_loss: 0.0255\n",
      "Epoch 47/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.9952 - loss: 0.0107 - val_accuracy: 0.9909 - val_loss: 0.0252\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9913 - loss: 0.0136 - val_accuracy: 0.9909 - val_loss: 0.0254\n",
      "Epoch 49/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9954 - loss: 0.0108 - val_accuracy: 0.9909 - val_loss: 0.0256\n",
      "Epoch 50/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0081 - val_accuracy: 0.9909 - val_loss: 0.0268\n",
      "Epoch 51/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.9909 - val_loss: 0.0256\n",
      "Epoch 52/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0110 - val_accuracy: 0.9909 - val_loss: 0.0270\n",
      "Epoch 53/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0093 - val_accuracy: 0.9909 - val_loss: 0.0281\n",
      "Epoch 54/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0134 - val_accuracy: 0.9909 - val_loss: 0.0292\n",
      "Epoch 55/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0106 - val_accuracy: 0.9909 - val_loss: 0.0274\n",
      "Epoch 56/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0088 - val_accuracy: 0.9909 - val_loss: 0.0281\n",
      "Epoch 57/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 0.9909 - val_loss: 0.0291\n",
      "Epoch 58/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0133 - val_accuracy: 0.9909 - val_loss: 0.0292\n",
      "Epoch 59/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9909 - val_loss: 0.0296\n",
      "Epoch 60/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0067 - val_accuracy: 0.9909 - val_loss: 0.0306\n",
      "Epoch 61/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9909 - val_loss: 0.0310\n",
      "Epoch 62/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9909 - val_loss: 0.0317\n",
      "Epoch 63/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9909 - val_loss: 0.0324\n",
      "Epoch 64/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0051 - val_accuracy: 0.9909 - val_loss: 0.0332\n",
      "Epoch 65/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9909 - val_loss: 0.0328\n",
      "Epoch 66/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9909 - val_loss: 0.0321\n",
      "Epoch 67/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9909 - val_loss: 0.0336\n",
      "Epoch 68/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9909 - val_loss: 0.0335\n",
      "Epoch 69/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9909 - val_loss: 0.0334\n",
      "Epoch 70/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9909 - val_loss: 0.0356\n",
      "Epoch 71/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9909 - val_loss: 0.0353\n",
      "Epoch 72/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9909 - val_loss: 0.0364\n",
      "Epoch 73/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9909 - val_loss: 0.0365\n",
      "Epoch 74/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9909 - val_loss: 0.0369\n",
      "Epoch 75/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9909 - val_loss: 0.0369\n",
      "Epoch 76/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9909 - val_loss: 0.0392\n",
      "Epoch 77/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9909 - val_loss: 0.0383\n",
      "Epoch 78/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9909 - val_loss: 0.0391\n",
      "Epoch 79/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9909 - val_loss: 0.0392\n",
      "Epoch 80/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9909 - val_loss: 0.0405\n",
      "Epoch 81/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9909 - val_loss: 0.0401\n",
      "Epoch 82/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9909 - val_loss: 0.0391\n",
      "Epoch 83/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9909 - val_loss: 0.0424\n",
      "Epoch 84/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9909 - val_loss: 0.0428\n",
      "Epoch 85/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9909 - val_loss: 0.0404\n",
      "Epoch 86/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9909 - val_loss: 0.0418\n",
      "Epoch 87/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9909 - val_loss: 0.0442\n",
      "Epoch 88/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9909 - val_loss: 0.0443\n",
      "Epoch 89/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9909 - val_loss: 0.0447\n",
      "Epoch 90/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9909 - val_loss: 0.0464\n",
      "Epoch 91/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9909 - val_loss: 0.0457\n",
      "Epoch 92/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9909 - val_loss: 0.0473\n",
      "Epoch 93/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9909 - val_loss: 0.0479\n",
      "Epoch 94/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9909 - val_loss: 0.0473\n",
      "Epoch 95/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9909 - val_loss: 0.0472\n",
      "Epoch 96/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9909 - val_loss: 0.0476\n",
      "Epoch 97/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9909 - val_loss: 0.0498\n",
      "Epoch 98/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9909 - val_loss: 0.0503\n",
      "Epoch 99/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9909 - val_loss: 0.0511\n",
      "Epoch 100/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9909 - val_loss: 0.0508\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Confusion Matrix for X3_X4_X5:\n",
      "[[118   1   0]\n",
      " [  0   7   0]\n",
      " [  0   0  11]]\n",
      "Test Accuracy for X3_X4_X5: 0.9927007299270073, Test Loss: 0.014606788754463196\n",
      "Training model with features: ['X1', 'X2', 'X3', 'X4', 'X5']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4175 - loss: 1.1205 - val_accuracy: 0.7636 - val_loss: 0.9180\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8583 - loss: 0.8329 - val_accuracy: 0.8455 - val_loss: 0.7196\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8550 - loss: 0.6464 - val_accuracy: 0.8455 - val_loss: 0.5741\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.5194 - val_accuracy: 0.8455 - val_loss: 0.4835\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.3957 - val_accuracy: 0.8455 - val_loss: 0.4281\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.3159 - val_accuracy: 0.8545 - val_loss: 0.3843\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8927 - loss: 0.3217 - val_accuracy: 0.8545 - val_loss: 0.3434\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2629 - val_accuracy: 0.8818 - val_loss: 0.3133\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.9287 - loss: 0.2216 - val_accuracy: 0.8818 - val_loss: 0.2846\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9277 - loss: 0.2041 - val_accuracy: 0.8818 - val_loss: 0.2587\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9240 - loss: 0.1933 - val_accuracy: 0.8818 - val_loss: 0.2299\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.1907 - val_accuracy: 0.8818 - val_loss: 0.2040\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.1818 - val_accuracy: 0.8818 - val_loss: 0.1812\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.9398 - loss: 0.1211 - val_accuracy: 0.8818 - val_loss: 0.1654\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.9488 - loss: 0.1090 - val_accuracy: 0.9636 - val_loss: 0.1402\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9846 - loss: 0.1056 - val_accuracy: 0.9818 - val_loss: 0.1203\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0945 - val_accuracy: 0.9818 - val_loss: 0.1054\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9867 - loss: 0.0963 - val_accuracy: 0.9818 - val_loss: 0.0930\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0652 - val_accuracy: 0.9818 - val_loss: 0.0833\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0533 - val_accuracy: 0.9818 - val_loss: 0.0739\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9896 - loss: 0.0704 - val_accuracy: 0.9909 - val_loss: 0.0676\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0470 - val_accuracy: 0.9909 - val_loss: 0.0628\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9976 - loss: 0.0344 - val_accuracy: 0.9909 - val_loss: 0.0588\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.9921 - loss: 0.0397 - val_accuracy: 0.9909 - val_loss: 0.0518\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.9868 - loss: 0.0539 - val_accuracy: 0.9909 - val_loss: 0.0493\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9924 - loss: 0.0404 - val_accuracy: 0.9909 - val_loss: 0.0476\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.9918 - loss: 0.0312 - val_accuracy: 0.9909 - val_loss: 0.0470\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0247 - val_accuracy: 0.9909 - val_loss: 0.0429\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0385 - val_accuracy: 0.9909 - val_loss: 0.0407\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0269 - val_accuracy: 0.9909 - val_loss: 0.0384\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9949 - loss: 0.0255 - val_accuracy: 0.9909 - val_loss: 0.0396\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9954 - loss: 0.0195 - val_accuracy: 0.9909 - val_loss: 0.0390\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9950 - loss: 0.0202 - val_accuracy: 0.9909 - val_loss: 0.0357\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9861 - loss: 0.0372 - val_accuracy: 0.9909 - val_loss: 0.0357\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0182 - val_accuracy: 0.9909 - val_loss: 0.0355\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9909 - loss: 0.0190 - val_accuracy: 0.9909 - val_loss: 0.0350\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0142 - val_accuracy: 0.9909 - val_loss: 0.0372\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0260 - val_accuracy: 0.9909 - val_loss: 0.0353\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9900 - loss: 0.0219 - val_accuracy: 0.9909 - val_loss: 0.0336\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0161 - val_accuracy: 0.9909 - val_loss: 0.0341\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0144 - val_accuracy: 0.9909 - val_loss: 0.0361\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9926 - loss: 0.0198 - val_accuracy: 0.9909 - val_loss: 0.0338\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9912 - loss: 0.0231 - val_accuracy: 0.9909 - val_loss: 0.0340\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0139 - val_accuracy: 0.9909 - val_loss: 0.0354\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0117 - val_accuracy: 0.9909 - val_loss: 0.0365\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0159 - val_accuracy: 0.9909 - val_loss: 0.0336\n",
      "Epoch 47/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0113 - val_accuracy: 0.9909 - val_loss: 0.0349\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0115 - val_accuracy: 0.9909 - val_loss: 0.0337\n",
      "Epoch 49/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0085 - val_accuracy: 0.9909 - val_loss: 0.0337\n",
      "Epoch 50/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0109 - val_accuracy: 0.9909 - val_loss: 0.0346\n",
      "Epoch 51/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.9909 - val_loss: 0.0355\n",
      "Epoch 52/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0156 - val_accuracy: 0.9909 - val_loss: 0.0349\n",
      "Epoch 53/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0102 - val_accuracy: 0.9909 - val_loss: 0.0340\n",
      "Epoch 54/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0102 - val_accuracy: 0.9909 - val_loss: 0.0342\n",
      "Epoch 55/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0123 - val_accuracy: 0.9909 - val_loss: 0.0361\n",
      "Epoch 56/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0147 - val_accuracy: 0.9909 - val_loss: 0.0335\n",
      "Epoch 57/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 0.9909 - val_loss: 0.0350\n",
      "Epoch 58/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0101 - val_accuracy: 0.9909 - val_loss: 0.0348\n",
      "Epoch 59/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0086 - val_accuracy: 0.9909 - val_loss: 0.0363\n",
      "Epoch 60/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0056 - val_accuracy: 0.9909 - val_loss: 0.0346\n",
      "Epoch 61/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0116 - val_accuracy: 0.9909 - val_loss: 0.0355\n",
      "Epoch 62/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0094 - val_accuracy: 0.9909 - val_loss: 0.0358\n",
      "Epoch 63/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0102 - val_accuracy: 0.9909 - val_loss: 0.0360\n",
      "Epoch 64/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.9957 - loss: 0.0081 - val_accuracy: 0.9909 - val_loss: 0.0362\n",
      "Epoch 65/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0080 - val_accuracy: 0.9909 - val_loss: 0.0366\n",
      "Epoch 66/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0086 - val_accuracy: 0.9909 - val_loss: 0.0374\n",
      "Epoch 67/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0078 - val_accuracy: 0.9909 - val_loss: 0.0391\n",
      "Epoch 68/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0120 - val_accuracy: 0.9909 - val_loss: 0.0339\n",
      "Epoch 69/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0073 - val_accuracy: 0.9909 - val_loss: 0.0365\n",
      "Epoch 70/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0064 - val_accuracy: 0.9909 - val_loss: 0.0370\n",
      "Epoch 71/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9909 - val_loss: 0.0390\n",
      "Epoch 72/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9909 - val_loss: 0.0382\n",
      "Epoch 73/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9909 - val_loss: 0.0390\n",
      "Epoch 74/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9909 - val_loss: 0.0408\n",
      "Epoch 75/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9909 - val_loss: 0.0375\n",
      "Epoch 76/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0052 - val_accuracy: 0.9909 - val_loss: 0.0390\n",
      "Epoch 77/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9909 - val_loss: 0.0396\n",
      "Epoch 78/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9909 - val_loss: 0.0395\n",
      "Epoch 79/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9909 - val_loss: 0.0393\n",
      "Epoch 80/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9909 - val_loss: 0.0416\n",
      "Epoch 81/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9909 - val_loss: 0.0393\n",
      "Epoch 82/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9909 - val_loss: 0.0400\n",
      "Epoch 83/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9909 - val_loss: 0.0414\n",
      "Epoch 84/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9909 - val_loss: 0.0427\n",
      "Epoch 85/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9909 - val_loss: 0.0418\n",
      "Epoch 86/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9909 - val_loss: 0.0429\n",
      "Epoch 87/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9909 - val_loss: 0.0423\n",
      "Epoch 88/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9909 - val_loss: 0.0423\n",
      "Epoch 89/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9909 - val_loss: 0.0434\n",
      "Epoch 90/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9909 - val_loss: 0.0430\n",
      "Epoch 91/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9909 - val_loss: 0.0436\n",
      "Epoch 92/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9909 - val_loss: 0.0439\n",
      "Epoch 93/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9909 - val_loss: 0.0439\n",
      "Epoch 94/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9909 - val_loss: 0.0450\n",
      "Epoch 95/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9909 - val_loss: 0.0450\n",
      "Epoch 96/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9909 - val_loss: 0.0443\n",
      "Epoch 97/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9909 - val_loss: 0.0449\n",
      "Epoch 98/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9909 - val_loss: 0.0460\n",
      "Epoch 99/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9909 - val_loss: 0.0471\n",
      "Epoch 100/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9909 - val_loss: 0.0463\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Confusion Matrix for All:\n",
      "[[119   0   0]\n",
      " [  1   6   0]\n",
      " [  0   0  11]]\n",
      "Test Accuracy for All: 0.9927007299270073, Test Loss: 0.05464600399136543\n",
      "All results:\n",
      "X3_X4: Accuracy = 1.0, Loss = 0.004880738910287619\n",
      "X3_X5: Accuracy = 0.9781021897810219, Loss = 0.0938430055975914\n",
      "X3_X4_X5: Accuracy = 0.9927007299270073, Loss = 0.014606788754463196\n",
      "All: Accuracy = 0.9927007299270073, Loss = 0.05464600399136543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Iterate over each feature set\n",
    "results = {}\n",
    "for name, features in feature_sets.items():\n",
    "    print(f\"Training model with features: {features}\")\n",
    "    \n",
    "    # Select the features for the current model\n",
    "    X = data[features]\n",
    "    y = data[['target_r', 'target_g', 'target_b']]  \n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Build the neural network model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)  # highest prob\n",
    "    y_true_labels = np.argmax(y_test.to_numpy(), axis=1)  # Covert\n",
    "    \n",
    "    # Evaluate the predictions\n",
    "    test_accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    \n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cm}\")\n",
    "    \n",
    "    # Only retrieve the loss\n",
    "    test_loss = model.evaluate(X_test_scaled, y_test, verbose=0)[0]  \n",
    "    print(f\"Test Accuracy for {name}: {test_accuracy}, Test Loss: {test_loss}\")\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {'Accuracy': test_accuracy, 'Loss': test_loss, 'Confusion Matrix': cm}\n",
    "\n",
    "# Print all results\n",
    "print(\"All results:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}: Accuracy = {metrics['Accuracy']}, Loss = {metrics['Loss']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f'Accuracy for {name}')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools\n",
    "\n",
    "# Define the encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Example: Let's say you have categorical labels\n",
    "data['target'] = encoder.fit_transform(data['target'])\n",
    "\n",
    "# plot for confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "classes = encoder.classes_\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Labeling for cm\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j],\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2: Twitter Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id       entity sentiment_label  \\\n",
      "0      2401  Borderlands        Positive   \n",
      "1      2401  Borderlands        Positive   \n",
      "2      2401  Borderlands        Positive   \n",
      "3      2401  Borderlands        Positive   \n",
      "4      2401  Borderlands        Positive   \n",
      "5      2402  Borderlands        Positive   \n",
      "6      2402  Borderlands        Positive   \n",
      "7      2402  Borderlands        Positive   \n",
      "8      2402  Borderlands        Positive   \n",
      "9      2402  Borderlands        Positive   \n",
      "\n",
      "                                          tweet_text  \n",
      "0  I am coming to the borders and I will kill you...  \n",
      "1  im getting on borderlands and i will kill you ...  \n",
      "2  im coming on borderlands and i will murder you...  \n",
      "3  im getting on borderlands 2 and i will murder ...  \n",
      "4  im getting into borderlands and i can murder y...  \n",
      "5  So I spent a few hours making something for fu...  \n",
      "6  So I spent a couple of hours doing something f...  \n",
      "7  So I spent a few hours doing something for fun...  \n",
      "8  So I spent a few hours making something for fu...  \n",
      "9  2010 So I spent a few hours making something f...  \n",
      "   tweet_id                entity sentiment_label  \\\n",
      "0       352                Amazon         Neutral   \n",
      "1      8312             Microsoft        Negative   \n",
      "2      4371                 CS-GO        Negative   \n",
      "3      4433                Google         Neutral   \n",
      "4      6273                  FIFA        Negative   \n",
      "5      7925             MaddenNFL        Positive   \n",
      "6     11332  TomClancysRainbowSix        Positive   \n",
      "7      1107        AssassinsCreed        Positive   \n",
      "8      2069            CallOfDuty        Negative   \n",
      "9      3185                 Dota2        Positive   \n",
      "\n",
      "                                          tweet_text  \n",
      "0  BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
      "1  @Microsoft Why do I pay for WORD when it funct...  \n",
      "2  CSGO matchmaking is so full of closet hacking,...  \n",
      "3  Now the President is slapping Americans in the...  \n",
      "4  Hi @EAHelp I’ve had Madeleine McCann in my cel...  \n",
      "5  Thank you @EAMaddenNFL!! \\n\\nNew TE Austin Hoo...  \n",
      "6  Rocket League, Sea of Thieves or Rainbow Six: ...  \n",
      "7  my ass still knee-deep in Assassins Creed Odys...  \n",
      "8  FIX IT JESUS ! Please FIX IT ! What In the wor...  \n",
      "9  The professional dota 2 scene is fucking explo...  \n"
     ]
    }
   ],
   "source": [
    "# import twitter data for problem 2\n",
    "twitter_training_df = pd.read_csv('twitter_training.csv')\n",
    "twitter_training_df.columns = ['tweet_id', 'entity', 'sentiment_label', 'tweet_text']\n",
    "twitter_validation_df = pd.read_csv('twitter_validation.csv')\n",
    "twitter_validation_df.columns = ['tweet_id', 'entity', 'sentiment_label', 'tweet_text']\n",
    "\n",
    "# Check\n",
    "print(twitter_training_df.head(10))\n",
    "print(twitter_validation_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8908908908908909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.91      0.85      0.88       171\n",
      "    Negative       0.90      0.93      0.92       266\n",
      "     Neutral       0.89      0.87      0.88       285\n",
      "    Positive       0.87      0.90      0.88       277\n",
      "\n",
      "    accuracy                           0.89       999\n",
      "   macro avg       0.89      0.89      0.89       999\n",
      "weighted avg       0.89      0.89      0.89       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple spaces with single space and strip leading/trailing spaces\n",
    "    \n",
    "    # Tokenization and stopword removal\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the preprocessing function\n",
    "twitter_training_df['processed_text'] = twitter_training_df['tweet_text'].apply(preprocess_text)\n",
    "twitter_validation_df['processed_text'] = twitter_validation_df['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(twitter_training_df['processed_text'])\n",
    "X_val = vectorizer.transform(twitter_validation_df['processed_text'])\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(twitter_training_df['sentiment_label'])\n",
    "y_val = encoder.transform(twitter_validation_df['sentiment_label'])\n",
    "\n",
    "# Initialize the DT\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train \n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = tree_classifier.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "print(classification_report(y_val, y_val_pred, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm_dt = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
